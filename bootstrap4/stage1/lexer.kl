struct LexStream:
    file str
    src str
    iter PeekableIterator<char>
end

impl LexStream:
    fn new(file str, src str) LexStream:
        let iter = PeekableIterator<char>.new(src.iter())
        LexStream{file: file, src: src, iter: iter}
    end

    fn span(self) Span:
        Span{file: self.file, src: self.src, from: self.iter.idx, to: self.iter.idx}
    end
end

impl Iterator<Token> for LexStream:
    fn next(mut self) Token?:
        let next = match self.iter.next():
            Some<char>(c) => c
            None => return None
        end
        let span = self.span()
        match next:
            ' ' | '\n' | '\t' | '\r' => Token{kind: WhiteSpace(next), span: span}
            '-' =>
                match self.iter.peek():
                    Some<char>('-') => self.match_comment()
                    _ => Token{kind: Minus, span: span.combine(self.span())}
                end
            '(' => Token{kind: Lparen, span: span}
            ')' => Token{kind: Rparen, span: span}
            ':' => Token{kind: Colon, span: span}
            '=' => 
                match self.iter.peek():
                    Some<char>('='):
                        self.iter.next()
                        Token{kind: DoubleEqual, span: span.combine(self.span())}
                    end
                    Some<char>('>'):
                        self.iter.next()
                        Token{kind: FatArrow, span: span.combine(self.span())}
                    end
                    _ => Token{kind: Equal, span: span}
                end
            '<' =>
                match self.iter.peek():
                    Some<char>('='):
                        self.iter.next()
                        Token{kind: LessThanOrEqual, span: span.combine(self.span())}
                    end
                    _ => Token{kind: LessThan, span: span}
                end
            '>' =>
                match self.iter.peek():
                    Some<char>('='):
                        self.iter.next()
                        Token{kind: GreaterThanOrEqual, span: span.combine(self.span())}
                    end
                    _ => Token{kind: GreaterThan, span: span}
                end
            '0'..'9':
                mut num = "".push_char(next)
                loop:
                    match self.iter.peek():
                        Some<char>('0'..'9') => num.push_char(self.iter.next().unwrap())
                        _ => break
                    end
                end
                Token{kind: Integer(num), span: span}
            end
            'a'..'z' | 'A'..'Z' | '_':
                mut ident = "".push_char(next)
                loop:
                    match self.iter.peek():
                        Some<char>('a'..'z' | 'A'..'Z' | '0'..'9' | '_'):
                            ident.push_char(self.iter.next().unwrap())
                        end
                        _ => break
                    end
                end
                match ident:
                    "fn" => Token{kind: Fn, span: span}
                    _ => Token{kind: Ident(ident), span: span}
                end
            end
            _ => Token{kind: ParseError(f"Unexpected character: {next}"), span: span}
        end
    end

    fn match_comment(mut self) Token:
        let span = self.span()
        self.iter.next()
        -- Single- or multi-line comment.
        mut comment = "--"
        match self.iter.next():
            Some<char>('-'):
                -- Multi-line comment.
                comment.push_char('-')
                mut num_of_dashes = 0
                loop:
                    match self.iter.next():
                        Some<char>('-'):
                            comment.push_char('-')
                            num_of_dashes = num_of_dashes + 1
                            if num_of_dashes == 3:
                                break
                            end
                        end
                        Some<char>(c):
                            comment.push_char(c)
                            num_of_dashes = 0
                        end
                        None => break
                    end
                end
            end
            Some<char>(c):
                -- Single-line comment.
                comment.push_char(c)
                loop:
                    match self.iter.peek():
                        Some<char>('\n') => break
                        Some<char>(c): 
                            comment.push_char(c)
                            self.iter.next()
                        end
                        None => break
                    end
                end
            end
            _ => None 
        end
        Token{kind: Comment(comment), span: span}
    end
end

struct Span:
    file str
    src str
    from i32
    to i32
end

impl Span:
    fn combine(self, other Span) Span:
        Span{
            file: self.file, 
            src: self.src, 
            from: if self.from < other.from => self.from else => other.from, 
            to: if self.to > other.to => self.to else => other.to
        }
    end
end

impl ToStr for Span:
    fn to_str(self) str:
        -- First, calculate the line and column numbers.
        fn line_col(pos i32) (i32, i32):
            mut line = 1
            mut col = 1
            mut iter = self.src.iter()
            mut idx = 0
            loop:
                match iter.next():
                    Some<char>('\n'):
                        line = line + 1
                        col = 1
                    end
                    Some<char>(c) => col = col + 1
                    None => break
                end
                if idx == pos => break
                idx = idx + 1
            end
            return (line, col)
        end
        let from = line_col(self.from)
        if self.from == self.to => return f"{self.file}:{from.0}:{from.1}"
        let to = line_col(self.to)
        if from.0 == to.0 => return f"{self.file}:{from.0}:{from.1}-{to.1}"
        f"{self.file}:{from.0}:{from.1}-{to.0}:{to.1}"
    end
end

enum TokenKind:
    Bool(bool)
    Colon
    Comment(str)
    DoubleEqual
    Equal
    FatArrow
    Fn
    GreaterThan
    GreaterThanOrEqual
    Ident(str)
    LessThan
    LessThanOrEqual
    Lparen
    Minus
    Integer(str)
    ParseError(str)
    Rparen
    Str(str)
    WhiteSpace(char)
end

impl ToStr for TokenKind:
    fn to_str(self) str:
        match self:
            Bool(b) => f"Bool({b})"
            Colon => ":"
            Comment(comment) => f"Comment({comment})"
            DoubleEqual => "=="
            Equal => "="
            FatArrow => "=>"
            Fn => "Fn"
            GreaterThan => ">"
            GreaterThanOrEqual => ">="
            Ident(ident) => f"Ident({ident})"
            LessThan => "<"
            LessThanOrEqual => "<="
            Lparen => "("
            Minus => "Minus"
            Integer(num) => f"Integer({num})"
            ParseError(msg) => f"ParseError({msg})"
            Rparen => ")"
            Str(s) => f"Str({s})"
            WhiteSpace(ws) => f"WhiteSpace()"
        end
    end
end

impl PartialEq for TokenKind:
    fn eq(self, other TokenKind) bool:
        -- todo: This is a hack, we should be able to derive `PartialEq`.
        self.to_str() == other.to_str()
    end
end

struct Token:
    kind TokenKind
    span Span
end

impl Token:
    fn to_src(self) str:
        match self.kind:
            Bool(b) => f"{b}"
            Colon => ":"
            Comment(comment) => comment
            DoubleEqual => "=="
            Equal => "="
            FatArrow => "=>"
            Fn => "fn"
            GreaterThan => ">"
            GreaterThanOrEqual => ">="
            Ident(ident) => ident
            LessThan => "<"
            LessThanOrEqual => "<="
            Lparen => "("
            Minus => "-"
            Integer(num) => num
            ParseError(msg) => f"ParseError({msg})"
            Rparen => ")"
            Str(s) => s
            WhiteSpace(ws) => f"{ws}"
        end
    end
end

impl ToStr for Token:
    fn to_str(self) str:
        f"{self.span} {self.kind}"
    end
end

fn lex(src str, file str) Vector<Token>:
    mut stream = LexStream.new(file, src)
    mut tokens = Vector<Token>.new()
    loop:
        match stream.next():
            Some<Token>(token) => tokens.push(token)
            None => break
        end
    end
    tokens
end

fn to_src(tokens Vector<Token>) str:
    --- Convert a vector of tokens back to source code.
        `lex()` and `to_src()` should be inverses of each other.
    ---
    mut s = ""
    tokens.iter().for_each(fn(token Token) => s.push(token.to_src());)
    s
end

-- todo: Convert to proper tests once we have the feature to add tests to modules.
fn main():
    fn test(src str, expected Array<TokenKind>):
        --- Test that `src` is lexed into `expected`. Whitespaces are ignored.
            Test that `lex()` and `to_src()` are inverses of each other.
        ---
        let tokens = lex(src, "test.kl")
        let parse_errors = tokens.iter().filter(
            fn(token Token) bool => match(token.kind):
                ParseError(_) => true
                _ => false
            end
        ).collect()
        if parse_errors.len() > 0:
            print("Parse errors:")
            parse_errors.iter().for_each(fn(token Token) => print(token))
            panic("Unexpected parse errors.")
        end
        mut idx = 0
        tokens.iter().filter(
            fn(token Token) bool => match(token.kind):
                WhiteSpace(_) => false
                _ => true
            end
        ).for_each(
            fn(token Token): 
                assert(idx < expected.len())
                assert(token.kind == expected[idx]) 
                idx = idx + 1
            end
        )
        assert(idx == expected.len())
        assert(to_src(tokens) == src)
    end
    test("x", [Ident("x")])
    test("x y", [Ident("x"), Ident("y")])
    -- Comments, Minus
    test("-- comment", [Comment("-- comment")])
    test("--- multi-line\ncomment --- x", [Comment("--- multi-line\ncomment ---"), Ident("x")])
    -- todo (lang-feat): Multi-line strings should be dedented automatically and have to option to be raw.
    test("""
--- Multi-line comment 
- with a dash
-- and a double dash
---
x
        """,
        [Comment("--- Multi-line comment \n- with a dash\n-- and a double dash\n---"), Ident("x")]
    )
    test("- -- comment", [Minus, Comment("-- comment")])
    -- =, ==, =>
    test("= == =>", [Equal, DoubleEqual, FatArrow])
    -- <, <=
    test("< <=", [LessThan, LessThanOrEqual])
    -- >, >=
    test("> >=", [GreaterThan, GreaterThanOrEqual])
    -- Integer
    test("123 12", [Integer("123"), Integer("12")])
    -- Identifier
    test("x Y _ a1 _a1 A1 _A1 a_1", [
        Ident("x"), Ident("Y"), Ident("_"), Ident("a1"), Ident("_a1"), 
        Ident("A1"), Ident("_A1"), Ident("a_1")
    ])
    -- Keywords
    test("fn", [Fn])
    print("All tests passed.")
end
