struct Lexer:
    file str
    src str
    iter PeekableIterator<char>
end

impl Lexer:
    fn lex(src str, file str) Iterator<Token>:
        let iter = PeekableIterator<char>.new(src.iter())
        Lexer{file, src, iter}
    end

    fn span(self) Span:
        Span{file: self.file, src: self.src, from: self.iter.idx, to: self.iter.idx}
    end
end

impl Iterator<Token> for Lexer:
    fn next(mut self) Token?:
        let next = match self.iter.next():
            Some<char>(c) => c
            None => return None
        end
        let span = self.span()
        match next:
            ' ' | '\n' | '\t' | '\r' => Token{kind: WhiteSpace(next), span}
            '-' =>
                match self.iter.peek():
                    Some<char>('-') => self.match_comment()
                    Some<char>('0'..'9') => self.match_int_literal(next, span)
                    _ => Token{kind: Minus, span: span.combine(self.span())}
                end
            '(' => Token{kind: LParen, span}
            ')' => Token{kind: RParen, span}
            '{' => Token{kind: LBrace, span}
            '}' => Token{kind: RBrace, span}
            '[' => Token{kind: LBracket, span}
            ']' => Token{kind: RBracket, span}
            '.' => Token{kind: Dot, span}
            ',' => Token{kind: Comma, span}
            ':' => Token{kind: Colon, span}
            '+' => Token{kind: Plus, span}
            '*' => Token{kind: Star, span}
            '/' => Token{kind: Slash, span}
            '!' => 
                match self.iter.peek():
                    Some<char>('='):
                        self.iter.next()
                        Token{kind: NotEqual, span: span.combine(self.span())}
                    end
                    _ => Token{kind: Exclamation, span}
                end
            '=' => 
                match self.iter.peek():
                    Some<char>('='):
                        self.iter.next()
                        Token{kind: DoubleEqual, span: span.combine(self.span())}
                    end
                    Some<char>('>'):
                        self.iter.next()
                        Token{kind: FatArrow, span: span.combine(self.span())}
                    end
                    _ => Token{kind: Equal, span}
                end
            '<' =>
                match self.iter.peek():
                    Some<char>('='):
                        self.iter.next()
                        Token{kind: LessThanOrEqual, span: span.combine(self.span())}
                    end
                    _ => Token{kind: LessThan, span}
                end
            '>' =>
                match self.iter.peek():
                    Some<char>('='):
                        self.iter.next()
                        Token{kind: GreaterThanOrEqual, span: span.combine(self.span())}
                    end
                    _ => Token{kind: GreaterThan, span}
                end
            '0'..'9' => self.match_int_literal(next, span)
            '"' => self.match_string(false)
            'a'..'z' | 'A'..'Z' | '_':
                if next == 'f':
                    match self.iter.peek():
                        Some<char>('"'):
                            self.iter.next()
                            return self.match_string(true)
                        end
                        _ => ()
                    end
                end
                mut ident = "".push_char(next)
                loop:
                    match self.iter.peek():
                        Some<char>('a'..'z' | 'A'..'Z' | '0'..'9' | '_'):
                            ident.push_char(self.iter.next().unwrap())
                        end
                        _ => break
                    end
                end
                let ident_span = span.combine(self.span())
                match ident:
                    -- todo (lang-feat): We should be able to generate this code automatically.
                    "and" => Token{kind: And, span: ident_span}
                    "break" => Token{kind: Break, span: ident_span}
                    "continue" => Token{kind: Continue, span: ident_span}
                    "else" => Token{kind: Else, span: ident_span}
                    "end" => Token{kind: End, span: ident_span}
                    "enum" => Token{kind: Enum, span: ident_span}
                    "extern" => Token{kind: Extern, span: ident_span}
                    "false" => Token{kind: Bool(false), span: ident_span}
                    "fn" => Token{kind: Fn, span: ident_span}
                    "for" => Token{kind: For, span: ident_span}
                    "if" => Token{kind: If, span: ident_span}
                    "impl" => Token{kind: Impl, span: ident_span}
                    "let" => Token{kind: Let, span: ident_span}
                    "loop" => Token{kind: Loop, span: ident_span}
                    "match" => Token{kind: Match, span: ident_span}
                    "mut" => Token{kind: Mut, span: ident_span}
                    "not" => Token{kind: Not, span: ident_span}
                    "or" => Token{kind: Or, span: ident_span}
                    "return" => Token{kind: Return, span: ident_span}
                    "struct" => Token{kind: Struct, span: ident_span}
                    "throws" => Token{kind: Throws, span: ident_span}
                    "trait" => Token{kind: Trait, span: ident_span}
                    "true" => Token{kind: Bool(true), span: ident_span}
                    "use" => Token{kind: Use, span: ident_span}
                    _ => Token{kind: Ident(ident), span: ident_span}
                end
            end
            _ => Token{kind: LexError(f"Unexpected character: {next}"), span}
        end
    end

    fn match_int_literal(mut self, first char, span Span) Token:
        mut num = "".push_char(first)
        loop:
            match self.iter.peek():
                Some<char>('0'..'9') => num.push_char(self.iter.next().unwrap())
                _ => break
            end
        end
        Token{kind: IntLiteral(num), span}
    end

    fn match_string(mut self, is_fstr bool) Token:
        let span = self.span()
        mut s = ""
        mut fstr_items = Vector<FStrItem>.new()
        mut quotes = ""
        let required_closing_quotes = match self.iter.peek():
            Some<char>('"'):
                self.iter.next()
                match self.iter.peek():
                    Some<char>('"'):
                        self.iter.next()
                        3
                    end
                    _ => 0 -- This is simply an empty string.
                end
            end
            _ => 1
        end
        let multi_line = required_closing_quotes == 3
        loop:
            if quotes.len() == required_closing_quotes:
                break
            end
            match self.iter.next():
                Some<char>('"'):
                    quotes.push_char('"')
                    continue
                end
                Some<char>('\\') => 
                    match match_escape_sequence(self.iter.next()):
                        Error(err) => return Token{kind: LexError(err.to_str()), span}
                        Ok<char>(c) => s.push_char(c)
                    end
                Some<char>('{'):
                    if not is_fstr:
                        s.push_char('{')
                        continue
                    end
                    if s.len() > 0:
                        fstr_items.push(FStrStrItem(s))
                        s = ""
                    end
                    mut item_tokens = Vector<Token>.new()
                    loop:
                        match self.iter.peek():
                            Some<char>('}'): 
                                self.iter.next()
                                break
                            end
                            None => return Token{kind: LexError("Unexpected end of file."), span: self.span()}
                            _ => item_tokens.push(self.next().unwrap())
                        end
                    end
                    fstr_items.push(FStrTokensItem(item_tokens))
                end
                Some<char>('\n') => 
                    if multi_line => s.push_char('\n')
                    else => return Token{kind: LexError("Unexpected end of line."), span: self.span()}
                Some<char>(c) => s.push_char(c)
                None => return Token{kind: LexError("Unexpected end of file."), span: self.span()}
            end
            quotes = ""
        end
        let kind = if is_fstr:
            if s.len() > 0:
                fstr_items.push(FStrStrItem(s))
            end
            FStr(fstr_items, multi_line)
        else => Str(s, multi_line)
        Token{kind, span: span.combine(self.span())}
    end

    fn match_comment(mut self) Token:
        let span = self.span()
        self.iter.next()
        -- Single- or multi-line comment.
        mut comment = "--"
        match self.iter.next():
            Some<char>('-'):
                -- Multi-line comment.
                comment.push_char('-')
                mut num_of_dashes = 0
                loop:
                    match self.iter.next():
                        Some<char>('-'):
                            comment.push_char('-')
                            num_of_dashes = num_of_dashes + 1
                            if num_of_dashes == 3:
                                break
                            end
                        end
                        Some<char>(c):
                            comment.push_char(c)
                            num_of_dashes = 0
                        end
                        None => break
                    end
                end
            end
            Some<char>(c):
                -- Single-line comment.
                comment.push_char(c)
                loop:
                    match self.iter.peek():
                        Some<char>('\n') => break
                        Some<char>(c): 
                            comment.push_char(c)
                            self.iter.next()
                        end
                        None => break
                    end
                end
            end
            _ => None 
        end
        Token{kind: Comment(comment), span}
    end
end

fn match_escape_sequence(c char?) char throws:
    match c:
        Some<char>('n') => '\n'
        Some<char>('r') => '\r'
        Some<char>('t') => '\t'
        Some<char>('"') => '"'
        Some<char>('\'') => '\''
        Some<char>('\\') => '\\'
        _ => return Error("Invalid escape sequence.")
    end
end

struct Span:
    file str
    src str
    from i32
    to i32
end

impl Span:
    fn combine(self, other Span) Span:
        Span{
            file: self.file, 
            src: self.src, 
            from: if self.from < other.from => self.from else => other.from, 
            to: if self.to > other.to => self.to else => other.to
        }
    end
end

impl ToStr for Span:
    fn to_str(self) str:
        -- First, calculate the line and column numbers.
        fn line_col(pos i32) (i32, i32):
            mut line = 1
            mut col = 1
            mut iter = self.src.iter()
            mut idx = 0
            loop:
                match iter.next():
                    Some<char>('\n'):
                        line = line + 1
                        col = 1
                    end
                    Some<char>(c) => col = col + 1
                    None => break
                end
                if idx == pos => break
                idx = idx + 1
            end
            return (line, col)
        end
        let from = line_col(self.from)
        if self.from == self.to => return f"{self.file}:{from.0}:{from.1}"
        let to = line_col(self.to)
        if from.0 == to.0 => return f"{self.file}:{from.0}:{from.1}-{to.1}"
        f"{self.file}:{from.0}:{from.1}-{to.0}:{to.1}"
    end
end

enum FStrItem:
    -- todo (lang-feat): We should only allow `Ident`, `Dot`, `LBracket`, and `RBracket` here.
    --                   Allowing arbitrary expressions leads to complex code. Perhaps this check
    --                   should be done in the parser instead.
    FStrTokensItem(Vector<Token>)
    FStrStrItem(str)
end

enum TokenKind:
    And
    Bool(bool)
    Break
    Colon
    Comma
    Comment(str)
    Continue
    Dot
    DoubleEqual
    Else
    End
    Enum
    Equal
    Exclamation
    Extern
    FatArrow
    Fn
    For
    FStr(Vector<FStrItem>, bool)
    GreaterThan
    GreaterThanOrEqual
    Ident(str)
    If
    Impl
    IntLiteral(str)
    LBrace
    LBracket
    LParen
    LessThan
    LessThanOrEqual
    Let
    Loop
    Match
    Minus
    Mut
    Not
    NotEqual
    Or
    LexError(str)
    Plus
    RBrace
    RBracket
    RParen
    Return
    Slash
    Star
    Str(str, bool)
    Struct
    Throws
    Trait
    Use
    WhiteSpace(char)
end

use TokenKind.*

impl ToStr for TokenKind:
    fn to_str(self) str:
        match self:
            -- todo (lang-feat): We should be able to generate most of this code automatically.
            And => "and"
            Bool(b) => f"Bool({b})"
            Break => "break"
            Colon => ":"
            Comma => ","
            Comment(comment) => f"Comment({comment})"
            Continue => "continue"
            Dot => "."
            DoubleEqual => "=="
            Else => "else"
            End => "end"
            Enum => "enum"
            Equal => "="
            Exclamation => "!"
            Extern => "extern"
            FatArrow => "=>"
            Fn => "fn"
            For => "for"
            FStr(items, is_multi_line):
                let items = items<FStrItem>.iter().map<str>(
                    fn(token FStrItem) str:
                        match token:
                            FStrTokensItem(tokens) => 
                                " ".join(
                                    tokens<Token>.iter().map<str>(
                                        fn(token Token) str => token.to_str()
                                    )
                                )
                            FStrStrItem(s) => s
                        end
                    end
                )
                let items_str = ", ".join(items)
                f"FStr([{items_str}], {is_multi_line})"
            end
            GreaterThan => ">"
            GreaterThanOrEqual => ">="
            Ident(ident) => f"Ident({ident})"
            If => "if"
            Impl => "impl"
            IntLiteral(num) => f"IntLiteral({num})"
            LBrace => "{"
            LBracket => "["
            LParen => "("
            LessThan => "<"
            LessThanOrEqual => "<="
            Let => "let"
            Loop => "loop"
            Match => "match"
            Minus => "-"
            Mut => "mut"
            Not => "not"
            NotEqual => "!="
            Or => "or"
            LexError(message) => f"LexError: {message}"
            Plus => "+"
            RBrace => "}"
            RBracket => "]"
            RParen => ")"
            Return => "return"
            Slash => "/"
            Star => "*"
            -- todo: escape string
            Str(s, multi_line) => f"Str({s}, {multi_line})"
            Struct => "struct"
            Throws => "throws"
            Trait => "trait"
            Use => "use"
            WhiteSpace(ws) => f"WhiteSpace()"
        end
    end
end

impl PartialEq for TokenKind:
    fn eq(self, other TokenKind) bool:
        -- todo: This is a hack, we should be able to derive `PartialEq`.
        self.to_str() == other.to_str()
    end
end

struct Token:
    kind TokenKind
    span Span
end

impl Token:
    fn to_src(self) str:
        --- Convert a token back to source code. This is done using the span to 
            slice the source code.
        ---
        match self.kind:
            Bool(b) => f"{b}"
            Comment(comment) => comment
            FStr(items, is_multi_line):
                let items = items<FStrItem>.iter().map<str>(
                    fn(token FStrItem) str:
                        match token:
                            FStrTokensItem(tokens) => 
                                "".join(
                                    tokens<Token>.iter().map<str>(
                                        fn(token Token) str => token.to_str()
                                    )
                                )
                            FStrStrItem(s) => s
                        end
                    end
                )
                let items_str = "".join(items)
                if is_multi_line => f"\"\"\"{items_str}\"\"\""
                else => f"\"{items_str}\""
            end
            Ident(ident) => ident
            IntLiteral(num) => num
            Str(s, multi_line) =>
                -- We use the actual source code to get the string literal
                -- as it was written in the source code. We need to do this
                -- because we can't distinguish between `\n` and `\\n` 
                -- in multi-line strings.
                self.span.src.slice_copy(self.span.from, self.span.to + 1)
            WhiteSpace(ws) => f"{ws}"
            _ => self.kind.to_str()
        end
    end
end

impl ToStr for Token:
    fn to_str(self) str:
        f"{self.kind}"
    end
end

fn to_src(tokens Vector<Token>) str:
    --- Convert a vector of tokens back to source code.
        `lex()` and `to_src()` should be inverses of each other.
    ---
    mut s = ""
    tokens.iter().for_each(fn(token Token) => s.push(token.to_src());)
    s
end
