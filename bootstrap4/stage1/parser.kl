--- = Parser 
    The parse parses a stream of tokens into a high level AST.

    == Desugaring

    Some of the syntactic sugar in the language will be converted
    to their canonical form by the parser:

    - `throws` will convert the return type to `Result<T, Error>`
    - `<type>?` will convert to `Option<type>`

    `Item.is_synthetic` is used to indicate whether the item
    has been altered by the parser as part of desugaring.
---
use .lexer.Token
use .lexer.TokenKind
use .ast.FnDef
use .ast.Literal
use .ast.Item
use .ast.Expr
use .ast.ParseError
use .ast.ParseErrorKind
use .ast.Block
use .ast.Meta
use .ast.FnDecl
use .ast.LiteralKind
use .ast.BlockItem

struct TokenIter:
    --- An iterator over tokens that can be peeked and rewound.
    ---
    tokens Vector<Token>
    peeked Token?
    idx i32
end

impl Iterator<Token> for TokenIter:
    fn next(mut self) Token?:
        if self.idx >= self.tokens.len() => return None
        if self.peeked.is_some():
            let value = self.peeked.unwrap()
            self.peeked = None
            value
        else:
            let value = self.tokens[self.idx]
            self.idx = self.idx + 1
            value
        end
    end

    fn force_next(mut self) Token throws ParseError:
        match self.next():
            Some<Token>(token) => Ok(token)
            None => return parse_error(UnexpectedEOF, None)
        end
    end

    fn force_peek(mut self) Token throws ParseError:
        match self.peeked:
            Some<Token>(token) => token
            None:
                let peeked = self.force_next()!
                self.peeked = Some<Token>(peeked)
                peeked
            end
        end
    end

    fn mark(self) i32 => self.idx 

    fn mark_prev(self) i32 => self.idx - 1

    fn reset(mut self, mark i32):
        self.peeked = None
        self.idx = mark
    end

    fn tokens_since(mut self, mark i32) Vector<Token>:
        --- Returns all tokens since the given mark (inclusive).
        ---
        if mark >= self.idx or mark < 0 => return Vector<Token>.new()
        self.tokens.slice_copy(mark, self.idx)
    end


    fn expect_ident(mut self) str throws ParseError:
        match self.force_next()!:
            Token{kind: Ident(name), span: _ } => Ok(name)
            token => return parse_error(UnexpectedToken(token), token)
        end
    end

    fn expect_token(mut self, predicate (fn(Token) bool)) Token throws ParseError:
        let token = self.force_next()!
        if not predicate(token) => return parse_error(UnexpectedToken(token), token)
        token
    end

    fn expect_lexical_token(mut self, kind TokenKind) Token throws ParseError:
        --- This only works with token that don't have any associated data.
        ---
        self.expect_token(fn(token Token) bool => token.kind == kind)!
    end
end

impl TokenIter:
    fn new(tokens Vector<Token>) TokenIter:
        -- Ignore all whitespace and comment tokens for now.
        let filtered_tokens = tokens.iter().filter(
            fn(token Token) bool => match token.kind:
                WhiteSpace(_) | Comment(_) => false
                _ => true
            end
        )
        TokenIter{tokens: filtered_tokens.collect(), peeked: None, idx: 0}
    end
end

struct Parser:
    iter TokenIter
end

impl Parser:

    fn new(iter TokenIter) Parser:
        Parser{iter}
    end

    fn parse(iter TokenIter) Item throws ParseError:
        -- The main entry point to parse a Klar module.
        let parser = Parser.new(iter)
        let token = parser.iter.force_next()!
        match parser.parse_item(token)!: 
            Some<Item>(item) => Ok(item)
            None => return parse_error(UnexpectedToken(token), token)
        end
    end

    fn parse_item(mut self, token Token) Item? throws ParseError:
        match token.kind:
            TokenKind.Fn => Item.FnDef(self.parse_fn(token)!)
            _ => return None
        end
    end

    fn parse_expr(mut self, token Token) Expr? throws ParseError:
        match token.kind:
            Integer(i) => Expr.Literal(self.parse_integer(i, token)!)
            _ => return None
        end
    end

    fn parse_integer(self, value str, token Token) Literal throws ParseError:
        let mark = self.iter.mark_prev()
        match i32.from_str(value):
            Ok<i32>(i) => Literal{kind: LiteralKind.Int(i), meta: self.meta(mark, false)}
            -- todo (lang-feat): The `return` should not be needed here. The stage0 type-checker
            --                   cannot infer that the result of the match is the return value 
            --                   of the function.
            Error(_) => return parse_error(InvalidIntLiteral(token), token)
        end
    end

    fn parse_fn(mut self, token Token) FnDef throws ParseError: 
        let mark = self.iter.mark_prev()
        let name = self.iter.expect_ident()!
        self.iter.expect_lexical_token(TokenKind.LParen)!
        self.iter.expect_lexical_token(TokenKind.RParen)!
        let decl = FnDecl{name, meta: self.meta(mark, false)}
        let body = self.parse_block()!
        FnDef{decl, body, meta: self.meta(mark, false)}
    end

    fn parse_block(mut self) Block throws ParseError:
        let mark = self.iter.mark()
        let items = Vector<BlockItem>.new() 
        self.iter.expect_lexical_token(TokenKind.Colon)!
        loop:
            let token = self.iter.force_next()!
            let item = match token.kind:
                TokenKind.End => break
                _ => self.parse_block_item(token)!
            end
            items.push(item)
        end
        Block{meta: self.meta(mark, false), items}
    end

    fn parse_block_item(mut self, token Token) BlockItem throws ParseError:
        let expr = self.parse_expr(token)!
        if expr.is_some() => return BlockItem.Expr(expr.unwrap())
        return parse_error(UnexpectedToken(token), token)
    end

    fn meta(self, mark i32, is_synthetic bool) Meta:
        Meta.new(self.iter.tokens_since(mark), is_synthetic)
    end
end

fn parse_error(kind ParseErrorKind, token Token?) Error<(), ParseError>:
    let tokens = if token.is_some() => Vector<Token>.from([token.unwrap()]) else => Vector<Token>.new()
    Error(ParseError{meta: Meta.new(tokens, false), kind})
end
