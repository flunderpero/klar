--- = Parser 
    The parse parses a stream of tokens into a high level AST.

    == Desugaring

    Some of the syntactic sugar in the language will be converted
    to their canonical form by the parser:

    - `throws` will convert the return type to `Result<T, Error>`
      as well as converting the return expression (both explicit and implicit)
      to `Ok(expr)`.
    - `<type>?` will convert to `Option<type>` as well as converting
      the return expression (both explicit and implicit) to `Some(expr)`.
      All optional call arguments will be converted to `Some(expr)` as well.

    `Item.is_synthetic` is used to indicate whether the item
    has been altered by the parser as part of desugaring.

    == TODO: Ambiguity

    These constructs are still ambiguous:

    - `if true => return func()`
        - Is this a return statement or a return expression? 
          Writing it as `if true: return end func()` or
          `if true: return func() end` would make it unambiguous.
        - We could remove the ambiguity here by requiring a return
          value in any case. The above would then be written as
          `if true => return () func()` which would be unambiguous.
---
use .ast.Block
use .ast.BlockItem
use .ast.Call
use .ast.Expr
use .ast.FnDecl
use .ast.FnDef
use .ast.FStr
use .ast.Ident
use .ast.Item
use .ast.Literal
use .ast.LiteralKind
use .ast.Meta
use .ast.ParseError
use .ast.ParseErrorKind
use .lexer.FStrItem
use .lexer.Token
use .lexer.TokenKind

use ParseErrorKind.*

struct TokenIter:
    --- An iterator over tokens that can be peeked and rewound.
    ---
    tokens Vector<Token>
    peeked Token?
    idx i32
end

impl Iterator<Token> for TokenIter:
    fn next(mut self) Token?:
        --- Return the next token or `None` ignoring whitespace and comments.
        ---
        loop:
            let token = self.immediate()
            match token:
                Some(
                    Token{kind: TokenKind.WhiteSpace(_) | TokenKind.Comment(_), span: _}
                ) => continue
                _ => return token
            end
        end
        -- todo (lang-feat): Semantic analysis should be able to infer that this is unreachable.
        None
    end

    fn immediate(mut self) Token?:
        --- Return the next token or `None` but including whitespace and comments.
        ---
        if self.idx >= self.tokens.len() => return None
        let v = if self.peeked.is_some():
            let value = self.peeked.unwrap()
            self.peeked = None
            value
        else:
            let value = self.tokens[self.idx]
            value
        end
        self.idx = self.idx + 1
        v
    end

    fn peek_immediate(mut self) Token?:
        --- Peek the next token (including whitespace and comments).
        ---
        if self.peeked.is_some() => return self.peeked
        if self.idx >= self.tokens.len() => return None
        let value = self.tokens[self.idx]
        self.peeked = Some(value)
        value
    end

    fn force_next(mut self) Token throws ParseError:
        --- Return the next token (excluding whitespace and commetns) or 
            an error if there are no more tokens.
        ---
        match self.next():
            Some<Token>(token) => Ok(token)
            None => return parse_error(UnexpectedEOF, None)
        end
    end

    fn force_immediate(mut self) Token throws ParseError:
        --- Return the next token (including whitespace and commetns) or 
            an error if there are no more tokens.
        ---
        match self.immediate():
            Some<Token>(token) => Ok(token)
            None => return parse_error(UnexpectedEOF, None)
        end
    end


    fn mark(self) i32 => self.idx 

    fn mark_prev(self) i32 => self.idx - 1

    fn reset(mut self, mark i32):
        self.peeked = None
        self.idx = mark
    end

    fn tokens_since(mut self, mark i32) Vector<Token>:
        --- Returns all tokens since the given mark (inclusive).
        ---
        if mark >= self.idx or mark < 0 => return Vector<Token>.new()
        self.tokens.slice_copy(mark, self.idx)
    end

    fn expect_ident(mut self) str throws ParseError:
        --- Expect the next token (without whitespace and comments) to be an identifier.
        ---
        match self.force_next()!:
            Token{kind: TokenKind.Ident(name), span: _ } => Ok(name)
            token => return parse_error(UnexpectedToken(token), token)
        end
    end

    fn expect_token(mut self, predicate (fn(Token) bool)) Token throws ParseError:
        --- Expect the next token (without whitespace and comments) to match the given predicate.
        ---
        let token = self.force_next()!
        if not predicate(token) => return parse_error(UnexpectedToken(token), token)
        token
    end

    fn expect_lexical_token(mut self, kind TokenKind) Token throws ParseError:
        --- Expect the next token (without whitespace and comments) to match the given kind.
        ---
        self.expect_token(fn(token Token) bool => token.kind == kind)!
    end

    fn expect_immediate_token(mut self, predicate (fn(Token) bool)) Token throws ParseError:
        --- Expect the next token (including whitespace and comments) to match the given predicate.
        ---
        let token = self.force_immediate()!
        if not predicate(token) => return parse_error(UnexpectedToken(token), token)
        token
    end

    fn expect_immediate_lexical_token(mut self, kind TokenKind) Token throws ParseError:
        --- Expect the next token (including whitespace and comments) to match the given kind.
        ---
        self.expect_immediate_token(fn(token Token) bool => token.kind == kind)!
    end
end

impl TokenIter:
    fn new(tokens Vector<Token>) TokenIter:
        TokenIter{tokens, peeked: None, idx: 0}
    end
end

struct Parser:
    iter TokenIter
end

impl Parser:

    fn new(iter TokenIter) Parser:
        Parser{iter}
    end

    fn parse(iter TokenIter) Item throws ParseError:
        -- The main entry point to parse a Klar module.
        let parser = Parser.new(iter)
        let token = parser.iter.force_next()!
        match parser.parse_item(token)!: 
            Some<Item>(item) => Ok(item)
            None => return parse_error(UnexpectedToken(token), token)
        end
    end

    fn parse_item(mut self, token Token) Item? throws ParseError:
        match token.kind:
            TokenKind.Fn => Item.FnDef(self.parse_fn_def(token)!)
            _ => return None
        end
    end

    fn parse_expr(mut self, token Token) Expr? throws ParseError:
        let mark = self.iter.mark_prev()
        mut expr = match token.kind:
            TokenKind.IntLiteral(i) => Expr.Literal(self.parse_int(i, token)!)
            TokenKind.BoolLiteral(b) => 
                Expr.Literal(Literal{kind: LiteralKind.Bool(b), meta: self.meta(mark, false)})
            TokenKind.StrLiteral(s, _) => 
                Expr.Literal(Literal{kind: LiteralKind.Str(s), meta: self.meta(mark, false)})
            TokenKind.LParen => self.parse_unit_or_tuple(token)!
            TokenKind.Ident(name) => Expr.Ident(Ident{name, meta: self.meta(mark, false)})
            TokenKind.FStr(items, _) => Expr.FStr(self.parse_fstr(items)!)
            _ => return None
        end
        loop:
            expr = match self.iter.peek_immediate():
                Some(Token{kind: TokenKind.LParen, span: _}) => 
                    Expr.Call(self.parse_call(expr)!)
                _ => break
            end
        end
        expr
    end

    fn parse_int(self, value str, token Token) Literal throws ParseError:
        let mark = self.iter.mark_prev()
        match i32.from_str(value):
            Ok<i32>(i) => Literal{kind: LiteralKind.Int(i), meta: self.meta(mark, false)}
            -- todo (lang-feat): The `return` should not be needed here. The stage0 type-checker
            --                   cannot infer that the result of the match is the return value 
            --                   of the function.
            Error(_) => return parse_error(InvalidIntLiteral(token), token)
        end
    end

    fn parse_unit_or_tuple(mut self, token Token) Expr throws ParseError:
        let mark = self.iter.mark_prev()
        let immediate = self.iter.immediate()
        match immediate:
            Some(Token{kind: TokenKind.RParen, span: _}):
                Expr.Literal(Literal{kind: LiteralKind.Unit, meta: self.meta(mark, false)})
            end
            _ => return parse_error(UnexpectedToken(immediate.unwrap()), immediate.unwrap())
        end 
    end

    fn parse_fstr(mut self, items Vector<FStrItem>) FStr throws ParseError:
        let mark = self.iter.mark_prev()
        mut exprs = Vector<Expr>.new()
        mut idx = 0
        -- todo (lang-feat): We tried to implement this with `items.iter().map()` but
        --                   we were not able to propagate errors from the map closure.
        loop:
            if idx >= items.len() => break
            let item = items[idx]
            idx = idx + 1
            let expr = match item:
                FStrItem.FStrTokensItem(tokens):
                    mut parser = Parser.new(TokenIter.new(tokens))
                    let expr = parser.parse_expr(parser.iter.force_next()!)!
                    match expr:
                        Some<Expr>(value) => value
                        None => return parse_error(ExprExpected(tokens[0]), tokens[0])
                    end
                end
                FStrItem.FStrStrItem(s):
                    Expr.Literal(Literal{kind: LiteralKind.Str(s), meta: self.meta(mark, false)})
                end
            end
            exprs.push(expr)
        end
        FStr{exprs, meta: self.meta(mark, false)}
    end

    fn parse_fn_def(mut self, token Token) FnDef throws ParseError: 
        let mark = self.iter.mark_prev()
        let name = self.iter.expect_ident()!
        self.iter.expect_lexical_token(TokenKind.LParen)!
        self.iter.expect_lexical_token(TokenKind.RParen)!
        let decl = FnDecl{name, meta: self.meta(mark, false)}
        let body = self.parse_block()!
        FnDef{decl, body, meta: self.meta(mark, false)}
    end

    fn parse_call(mut self, target Expr) Call throws ParseError:
        let mark = self.iter.mark()
        self.iter.expect_immediate_lexical_token(TokenKind.LParen)!
        let args = Vector<Expr>.new()
        mut got_comma = false
        loop:
            let next_token = self.iter.force_next()!
            match next_token.kind:
                TokenKind.RParen => break
                TokenKind.Comma:
                    if got_comma => return parse_error(ExprExpected(next_token), next_token)
                    got_comma = true
                    continue
                end
                _: 
                    if args.len() > 0 and not got_comma => 
                        return parse_error(UnexpectedToken(next_token), next_token)
                    got_comma = false
                    match self.parse_expr(next_token)!:
                        Some<Expr>(expr) => args.push(expr)
                        None => return parse_error(ExprExpected(next_token), next_token)
                    end
                end
            end
        end
        Call{target, args, meta: self.meta(mark, false)}
    end

    fn parse_block(mut self) Block throws ParseError:
        let mark = self.iter.mark()
        let items = Vector<BlockItem>.new() 
        self.iter.expect_lexical_token(TokenKind.Colon)!
        loop:
            let token = self.iter.force_next()!
            let item = match token.kind:
                TokenKind.End => break
                _ => self.parse_block_item(token)!
            end
            items.push(item)
        end
        Block{meta: self.meta(mark, false), items}
    end

    fn parse_block_item(mut self, token Token) BlockItem throws ParseError:
        let expr = self.parse_expr(token)!
        if expr.is_some() => return BlockItem.Expr(expr.unwrap())
        return parse_error(UnexpectedToken(token), token)
    end

    fn meta(self, mark i32, is_synthetic bool) Meta:
        Meta.new(self.iter.tokens_since(mark), is_synthetic)
    end
end

fn parse_error(kind ParseErrorKind, token Token?) Error<(), ParseError>:
    let tokens = if token.is_some() => Vector<Token>.from([token.unwrap()]) else => Vector<Token>.new()
    Error(ParseError{meta: Meta.new(tokens, false), kind})
end
